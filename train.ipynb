{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = focal_loss(pos_weight=5, gamma=0, label_smoothing=0.0)\n",
    "# # Y_true = tf.cast(np.array([0, 1, 1, 0, 1.00, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]), tf.float32)\n",
    "# # Y_pred = tf.cast(np.array([0, 1, 0, 1, 0.82, 0.9, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]), tf.float32)\n",
    "# Y_pred = tf.cast(np.arange(0, 1.01, 0.05), tf.float32)\n",
    "# Y_true = tf.ones_like(Y_pred, tf.float32)\n",
    "# loss(Y_true, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "\n",
    "import os, gc, sys, time, random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from google.cloud import storage\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.optimizers.utils import fit_bn\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import transformers\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "\n",
    "def focal_loss(gamma=2., pos_weight=1, label_smoothing=0.05):\n",
    "    def binary_focal_loss(labels, p):\n",
    "        labels = tf.dtypes.cast(labels, dtype=p.dtype)\n",
    "        if label_smoothing is not None:\n",
    "            labels = (1 - label_smoothing) * labels + label_smoothing * 0.5\n",
    "\n",
    "        # Predicted probabilities for the negative class\n",
    "        q = 1 - p\n",
    "\n",
    "        # For numerical stability (so we don't inadvertently take the log of 0)\n",
    "        p = tf.math.maximum(p, K.epsilon())\n",
    "        q = tf.math.maximum(q, K.epsilon())\n",
    "\n",
    "        # Loss for the positive examples\n",
    "        pos_loss = -(q ** gamma) * tf.math.log(p) * pos_weight\n",
    "\n",
    "        # Loss for the negative examples\n",
    "        neg_loss = -(p ** gamma) * tf.math.log(q)\n",
    "\n",
    "        # Combine loss terms\n",
    "        loss = labels * pos_loss + (1 - labels) * neg_loss\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    return binary_focal_loss\n",
    "\n",
    "\n",
    "def train(optimizer='LAMB',\n",
    "          lr=2e-5, weight_decay=1e-6,\n",
    "          moving_average=None,\n",
    "          loss_fn='bce',\n",
    "          label_smoothing=0.01,\n",
    "          pos_weight=5, gamma=2.0,  ## focal loss\n",
    "          epochs=30, stages=10,\n",
    "          dataset='../input/jigsaw-mltc-ds/jigsaw_mltc_ds436001s.npz',\n",
    "          gcs='hm-eu-w4',\n",
    "          path='jigsaw/test',\n",
    "          tpu_id=None,\n",
    "          seed=0):\n",
    "    args = pd.DataFrame(dict(locals()), index=[0])\n",
    "    print(args.T)\n",
    "    gc.collect()\n",
    "\n",
    "    if tpu_id is None:\n",
    "        with open('tpu', 'r') as content_file:\n",
    "            tpu_id = content_file.read()\n",
    "            print(dict(tpu_id=tpu_id))\n",
    "\n",
    "    ## Detect hardware, return appropriate distribution strategy\n",
    "    try:\n",
    "        # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "        # set: this is always the case on Kaggle.\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_id)\n",
    "        print('Running on TPU ', tpu.master())\n",
    "    except ValueError:\n",
    "        tpu = None\n",
    "\n",
    "    if tpu:\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    else:\n",
    "        # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "    print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "\n",
    "    ## Configuration\n",
    "    BATCH_SIZE = 24 * strategy.num_replicas_in_sync if tpu else 1\n",
    "    MAX_LEN = 192\n",
    "    AUTO = tf.data.experimental.AUTOTUNE\n",
    "    MODEL = 'jplu/tf-xlm-roberta-large'\n",
    "    path = f'{path}/{time.strftime(\"%Y%m%d_%H%M%S\")}_{tpu_id}'\n",
    "    gcs_path = f'gs://{gcs}/{path}'\n",
    "    print('Path:', gcs_path)\n",
    "    \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "    ## Load Dataset\n",
    "    valid = pd.read_csv('../input/jigsaw-multilingual-toxic-comment-classification/validation.csv')\n",
    "    test = pd.read_csv('../input/jigsaw-multilingual-toxic-comment-classification/test.csv')\n",
    "    sub = pd.read_csv('../input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv')\n",
    "\n",
    "    array = np.load(dataset)\n",
    "    x_train, x_valid, x_test, y_train, y_valid = [array[k] for k in list(array)]\n",
    "    assert x_train.dtype is np.dtype('int32')\n",
    "    print(x_train.shape, x_valid.shape, x_test.shape, y_train.shape, y_valid.shape)\n",
    "\n",
    "    train_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((x_train, y_train))\n",
    "        .repeat()\n",
    "        .shuffle(2048)\n",
    "        .batch(BATCH_SIZE)\n",
    "        .prefetch(AUTO)\n",
    "    )\n",
    "\n",
    "    valid_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((x_valid, y_valid))\n",
    "        .batch(BATCH_SIZE)\n",
    "        .cache()\n",
    "        .prefetch(AUTO)\n",
    "    )\n",
    "\n",
    "    test_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices(x_test)\n",
    "        .batch(BATCH_SIZE)\n",
    "    )\n",
    "\n",
    "    def build_model(transformer, max_len=512):\n",
    "        \"\"\" https://www.kaggle.com/xhlulu/jigsaw-tpu-distilbert-with-huggingface-and-keras \"\"\"\n",
    "        input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "        sequence_output = transformer(input_word_ids)[0]\n",
    "        cls_token = sequence_output[:, 0, :]\n",
    "        out = Dense(1, activation='sigmoid')(cls_token)\n",
    "        model = Model(inputs=input_word_ids, outputs=out)\n",
    "\n",
    "        if loss_fn == 'focal':\n",
    "            loss = focal_loss(pos_weight=pos_weight, gamma=gamma, label_smoothing=label_smoothing)\n",
    "        elif loss_fn == 'bce':\n",
    "            loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing)\n",
    "\n",
    "        if optimizer == 'LAMB':\n",
    "            opt = tfa.optimizers.LAMB(lr=lr, weight_decay_rate=weight_decay)\n",
    "        elif optimizer == 'AdamW':\n",
    "            opt = tfa.optimizers.AdamW(lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        if moving_average is not None and moving_average > 0:\n",
    "            opt = tfa.optimizers.MovingAverage(opt, average_decay=moving_average)\n",
    "\n",
    "        model.compile(\n",
    "                optimizer=opt,\n",
    "                loss=loss,\n",
    "                metrics=['accuracy', tf.keras.metrics.AUC(name='auc')]\n",
    "            )\n",
    "\n",
    "        return model\n",
    "    \n",
    "    with strategy.scope():\n",
    "        transformer_layer = TFAutoModel.from_pretrained(MODEL)\n",
    "        model = build_model(transformer_layer, max_len=MAX_LEN)\n",
    "\n",
    "    ## Train\n",
    "    lr_schedule = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.31,\n",
    "                                                       patience=2, cooldown=1,\n",
    "                                                       verbose=1, mode='max', min_delta=1e-4)\n",
    "#     stopping = tf.keras.callbacks.EarlyStopping(monitor='val_auc', min_delta=1e-4, mode='max',\n",
    "#                                                 patience=6, verbose=1, restore_best_weights=True)\n",
    "\n",
    "\n",
    "    checkpoint_path = f\"{gcs_path}/best_model.tf\"\n",
    "    cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                     monitor='val_auc', mode='max',\n",
    "                                                     verbose=1,\n",
    "                                                     save_best_only=True,\n",
    "                                                     save_weights_only=True)\n",
    "\n",
    "    n_steps = x_train.shape[0] // BATCH_SIZE\n",
    "#     try:\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch=n_steps // stages,\n",
    "        validation_data=valid_dataset,\n",
    "        epochs=epochs,\n",
    "#         callbacks=[lr_schedule, stopping, cp_callback],\n",
    "        callbacks=[lr_schedule, cp_callback],\n",
    "    )\n",
    "#     except Exception as ex:\n",
    "#         print(ex)\n",
    "#         history = model.history\n",
    "\n",
    "\n",
    "    def save_fig(filename, path=path, bucket=gcs):\n",
    "        fig.savefig(filename)\n",
    "        plt.close()\n",
    "        # init GCS client and upload file\n",
    "        client = storage.Client()\n",
    "        bucket = client.get_bucket('hm-eu-w4')\n",
    "        blob = bucket.blob(f'{path}/' + filename)\n",
    "        content = blob.upload_from_filename(filename=filename)\n",
    "\n",
    "    ## Eval and sub\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(18,4))\n",
    "    # Plot training & validation loss values\n",
    "    ax = axs[0]\n",
    "    ax.plot(history.history['loss'])\n",
    "    ax.plot(history.history['val_loss'])\n",
    "    ax.set_title('Model loss')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.legend(['Train', 'Test'], loc='lower left')\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    ax = axs[1]\n",
    "    ax.plot(history.history['accuracy'])\n",
    "    ax.plot(history.history['val_accuracy'])\n",
    "    ax.set_title('Model accuracy')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    ax = axs[2]\n",
    "    ax.plot(history.history['auc'])\n",
    "    ax.plot(history.history['val_auc'])\n",
    "    ax.set_title('Model AUC')\n",
    "    ax.set_ylabel('AUC')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "    save_fig('history.png')\n",
    "\n",
    "    # load best\n",
    "    # latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "    with strategy.scope():\n",
    "        model.load_weights(checkpoint_path)\n",
    "\n",
    "    valid['pred'] = model.predict(valid_dataset, verbose=1)\n",
    "    valid.to_csv(f'{gcs_path}/valid_oof.csv', index=False)\n",
    "\n",
    "    valid_auc = roc_auc_score(valid.toxic, valid.pred)\n",
    "\n",
    "    ax = valid.pred.hist(bins=100, log=True)\n",
    "    save_fig('valid_hist.png')\n",
    "    print('toxic:', valid.toxic.mean(), 'pred:', valid.pred.mean(), (valid.pred > 0.5).mean())\n",
    "    print('AUC:', valid_auc)\n",
    "\n",
    "    sub['toxic'] = model.predict(test_dataset, verbose=1)\n",
    "    sub.to_csv(f'{gcs_path}/submission.csv', index=False)\n",
    "\n",
    "    ax = sub.toxic.hist(bins=100, log=True)\n",
    "    save_fig('sub_hist.png')\n",
    "    print('mean:', sub.toxic.mean(), (sub.toxic > 0.5).mean())\n",
    "    \n",
    "    ## Save params\n",
    "    args['auc'] = valid_auc\n",
    "    args.to_csv(f'{gcs_path}/params{valid_auc:04f}.csv', index=False)\n",
    "    print(args.T)\n",
    "\n",
    "    return valid_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 0\n",
      "seed                                                             3\n",
      "tpu_id                                                         t8a\n",
      "path                                                  jigsaw/r000/\n",
      "gcs                                                       hm-eu-w4\n",
      "dataset          ../input/jigsaw-mltc-ds/jigsaw_mltc_ds436001s.npz\n",
      "stages                                                          10\n",
      "epochs                                                          30\n",
      "weight_decay                                           1.19879e-06\n",
      "pos_weight                                                 2.94862\n",
      "optimizer                                                     LAMB\n",
      "lr                                                     3.23753e-05\n",
      "loss_fn                                                      focal\n",
      "label_smoothing                                          0.0154527\n",
      "gamma                                                      1.00809\n",
      "Running on TPU  grpc://10.246.162.210:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: t8a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: t8a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  8\n",
      "Path: gs://hm-eu-w4/jigsaw/r000//20200422_141934_t8a\n",
      "(436001, 192) (8000, 192) (63812, 192) (436001,) (8000,)\n",
      "Train for 227 steps, validate for 42 steps\n",
      "Epoch 1/30\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "/home/henrique/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:430: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 256002048 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_roberta_model/roberta/pooler/dense/kernel:0', 'tf_roberta_model/roberta/pooler/dense/bias:0'] when minimizing the loss.\n",
      "/home/henrique/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/indexed_slices.py:430: UserWarning: Converting sparse IndexedSlices to a dense Tensor with 256002048 elements. This may consume a large amount of memory.\n",
      "  num_elements)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226/227 [============================>.] - ETA: 1s - loss: 0.3525 - accuracy: 0.6198 - auc: 0.7407\n",
      "Epoch 00001: val_auc improved from -inf to 0.92958, saving model to gs://hm-eu-w4/jigsaw/r000//20200422_141934_t8a/best_model.tf\n",
      "227/227 [==============================] - 427s 2s/step - loss: 0.3519 - accuracy: 0.6199 - auc: 0.7409 - val_loss: 0.2477 - val_accuracy: 0.8683 - val_auc: 0.9296\n",
      "Epoch 2/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.2272 - accuracy: 0.6574 - auc: 0.8148\n",
      "Epoch 00002: val_auc improved from 0.92958 to 0.93127, saving model to gs://hm-eu-w4/jigsaw/r000//20200422_141934_t8a/best_model.tf\n",
      "227/227 [==============================] - 229s 1s/step - loss: 0.2272 - accuracy: 0.6573 - auc: 0.8149 - val_loss: 0.2395 - val_accuracy: 0.8736 - val_auc: 0.9313\n",
      "Epoch 3/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.2170 - accuracy: 0.6654 - auc: 0.8151\n",
      "Epoch 00003: val_auc improved from 0.93127 to 0.94359, saving model to gs://hm-eu-w4/jigsaw/r000//20200422_141934_t8a/best_model.tf\n",
      "227/227 [==============================] - 228s 1s/step - loss: 0.2171 - accuracy: 0.6653 - auc: 0.8149 - val_loss: 0.2322 - val_accuracy: 0.8970 - val_auc: 0.9436\n",
      "Epoch 4/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.2086 - accuracy: 0.6682 - auc: 0.8229\n",
      "Epoch 00004: val_auc improved from 0.94359 to 0.94590, saving model to gs://hm-eu-w4/jigsaw/r000//20200422_141934_t8a/best_model.tf\n",
      "227/227 [==============================] - 219s 965ms/step - loss: 0.2084 - accuracy: 0.6685 - auc: 0.8231 - val_loss: 0.2262 - val_accuracy: 0.8931 - val_auc: 0.9459\n",
      "Epoch 5/30\n",
      "226/227 [============================>.] - ETA: 1s - loss: 0.2022 - accuracy: 0.6726 - auc: 0.8174\n",
      "Epoch 00005: val_auc improved from 0.94590 to 0.94828, saving model to gs://hm-eu-w4/jigsaw/r000//20200422_141934_t8a/best_model.tf\n",
      "227/227 [==============================] - 239s 1s/step - loss: 0.2021 - accuracy: 0.6727 - auc: 0.8175 - val_loss: 0.2141 - val_accuracy: 0.8868 - val_auc: 0.9483\n",
      "Epoch 6/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1989 - accuracy: 0.6743 - auc: 0.8116\n",
      "Epoch 00006: val_auc improved from 0.94828 to 0.95104, saving model to gs://hm-eu-w4/jigsaw/r000//20200422_141934_t8a/best_model.tf\n",
      "227/227 [==============================] - 231s 1s/step - loss: 0.1987 - accuracy: 0.6744 - auc: 0.8116 - val_loss: 0.2100 - val_accuracy: 0.8818 - val_auc: 0.9510\n",
      "Epoch 7/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1967 - accuracy: 0.6724 - auc: 0.8168\n",
      "Epoch 00007: val_auc improved from 0.95104 to 0.95497, saving model to gs://hm-eu-w4/jigsaw/r000//20200422_141934_t8a/best_model.tf\n",
      "227/227 [==============================] - 224s 986ms/step - loss: 0.1969 - accuracy: 0.6724 - auc: 0.8170 - val_loss: 0.2032 - val_accuracy: 0.8843 - val_auc: 0.9550\n",
      "Epoch 8/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1953 - accuracy: 0.6751 - auc: 0.8163\n",
      "Epoch 00008: val_auc improved from 0.95497 to 0.95619, saving model to gs://hm-eu-w4/jigsaw/r000//20200422_141934_t8a/best_model.tf\n",
      "227/227 [==============================] - 225s 992ms/step - loss: 0.1953 - accuracy: 0.6754 - auc: 0.8164 - val_loss: 0.2039 - val_accuracy: 0.8955 - val_auc: 0.9562\n",
      "Epoch 9/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1917 - accuracy: 0.6782 - auc: 0.8129\n",
      "Epoch 00009: val_auc did not improve from 0.95619\n",
      "227/227 [==============================] - 226s 996ms/step - loss: 0.1917 - accuracy: 0.6781 - auc: 0.8130 - val_loss: 0.2063 - val_accuracy: 0.8981 - val_auc: 0.9556\n",
      "Epoch 10/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1934 - accuracy: 0.6760 - auc: 0.8169\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 1.0036335443146526e-05.\n",
      "\n",
      "Epoch 00010: val_auc did not improve from 0.95619\n",
      "227/227 [==============================] - 159s 699ms/step - loss: 0.1935 - accuracy: 0.6757 - auc: 0.8167 - val_loss: 0.2234 - val_accuracy: 0.9169 - val_auc: 0.9553\n",
      "Epoch 11/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1888 - accuracy: 0.6767 - auc: 0.8212\n",
      "Epoch 00011: val_auc did not improve from 0.95619\n",
      "227/227 [==============================] - 159s 700ms/step - loss: 0.1888 - accuracy: 0.6765 - auc: 0.8213 - val_loss: 0.2068 - val_accuracy: 0.9020 - val_auc: 0.9559\n",
      "Epoch 12/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1854 - accuracy: 0.6777 - auc: 0.8131\n",
      "Epoch 00012: val_auc improved from 0.95619 to 0.95693, saving model to gs://hm-eu-w4/jigsaw/r000//20200422_141934_t8a/best_model.tf\n",
      "227/227 [==============================] - 160s 704ms/step - loss: 0.1853 - accuracy: 0.6778 - auc: 0.8129 - val_loss: 0.2018 - val_accuracy: 0.9046 - val_auc: 0.9569\n",
      "Epoch 13/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1850 - accuracy: 0.6804 - auc: 0.8122\n",
      "Epoch 00013: val_auc improved from 0.95693 to 0.95875, saving model to gs://hm-eu-w4/jigsaw/r000//20200422_141934_t8a/best_model.tf\n",
      "227/227 [==============================] - 226s 994ms/step - loss: 0.1850 - accuracy: 0.6803 - auc: 0.8121 - val_loss: 0.1981 - val_accuracy: 0.9006 - val_auc: 0.9588\n",
      "Epoch 14/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1829 - accuracy: 0.6815 - auc: 0.8129\n",
      "Epoch 00014: val_auc did not improve from 0.95875\n",
      "227/227 [==============================] - 212s 932ms/step - loss: 0.1829 - accuracy: 0.6815 - auc: 0.8129 - val_loss: 0.2099 - val_accuracy: 0.9159 - val_auc: 0.9579\n",
      "Epoch 15/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1801 - accuracy: 0.6832 - auc: 0.8164\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 3.111264122708235e-06.\n",
      "\n",
      "Epoch 00015: val_auc did not improve from 0.95875\n",
      "227/227 [==============================] - 159s 700ms/step - loss: 0.1800 - accuracy: 0.6836 - auc: 0.8165 - val_loss: 0.2098 - val_accuracy: 0.9156 - val_auc: 0.9580\n",
      "Epoch 16/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1807 - accuracy: 0.6831 - auc: 0.8122\n",
      "Epoch 00016: val_auc improved from 0.95875 to 0.95882, saving model to gs://hm-eu-w4/jigsaw/r000//20200422_141934_t8a/best_model.tf\n",
      "227/227 [==============================] - 160s 704ms/step - loss: 0.1807 - accuracy: 0.6831 - auc: 0.8121 - val_loss: 0.1979 - val_accuracy: 0.9023 - val_auc: 0.9588\n",
      "Epoch 17/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1801 - accuracy: 0.6805 - auc: 0.8158\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 9.644918554840842e-07.\n",
      "\n",
      "Epoch 00017: val_auc did not improve from 0.95882\n",
      "227/227 [==============================] - 220s 971ms/step - loss: 0.1801 - accuracy: 0.6805 - auc: 0.8158 - val_loss: 0.2019 - val_accuracy: 0.9090 - val_auc: 0.9588\n",
      "Epoch 18/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1786 - accuracy: 0.6841 - auc: 0.8176\n",
      "Epoch 00018: val_auc improved from 0.95882 to 0.95884, saving model to gs://hm-eu-w4/jigsaw/r000//20200422_141934_t8a/best_model.tf\n",
      "227/227 [==============================] - 160s 705ms/step - loss: 0.1787 - accuracy: 0.6839 - auc: 0.8176 - val_loss: 0.1995 - val_accuracy: 0.9069 - val_auc: 0.9588\n",
      "Epoch 19/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1758 - accuracy: 0.6875 - auc: 0.8172\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 2.9899247238063255e-07.\n",
      "\n",
      "Epoch 00019: val_auc did not improve from 0.95884\n",
      "227/227 [==============================] - 221s 972ms/step - loss: 0.1757 - accuracy: 0.6876 - auc: 0.8170 - val_loss: 0.2014 - val_accuracy: 0.9076 - val_auc: 0.9588\n",
      "Epoch 20/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1779 - accuracy: 0.6841 - auc: 0.8169\n",
      "Epoch 00020: val_auc improved from 0.95884 to 0.95899, saving model to gs://hm-eu-w4/jigsaw/r000//20200422_141934_t8a/best_model.tf\n",
      "227/227 [==============================] - 161s 708ms/step - loss: 0.1779 - accuracy: 0.6842 - auc: 0.8170 - val_loss: 0.2000 - val_accuracy: 0.9075 - val_auc: 0.9590\n",
      "Epoch 21/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1812 - accuracy: 0.6813 - auc: 0.8154\n",
      "Epoch 00021: val_auc did not improve from 0.95899\n",
      "227/227 [==============================] - 223s 984ms/step - loss: 0.1813 - accuracy: 0.6812 - auc: 0.8154 - val_loss: 0.2000 - val_accuracy: 0.9078 - val_auc: 0.9590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1792 - accuracy: 0.6811 - auc: 0.8130\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 9.268766291370412e-08.\n",
      "\n",
      "Epoch 00022: val_auc did not improve from 0.95899\n",
      "227/227 [==============================] - 159s 700ms/step - loss: 0.1791 - accuracy: 0.6810 - auc: 0.8131 - val_loss: 0.1997 - val_accuracy: 0.9071 - val_auc: 0.9589\n",
      "Epoch 23/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1783 - accuracy: 0.6843 - auc: 0.8155\n",
      "Epoch 00023: val_auc improved from 0.95899 to 0.95900, saving model to gs://hm-eu-w4/jigsaw/r000//20200422_141934_t8a/best_model.tf\n",
      "227/227 [==============================] - 160s 705ms/step - loss: 0.1782 - accuracy: 0.6843 - auc: 0.8154 - val_loss: 0.1997 - val_accuracy: 0.9071 - val_auc: 0.9590\n",
      "Epoch 24/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1771 - accuracy: 0.6846 - auc: 0.8139\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 2.8733175767570172e-08.\n",
      "\n",
      "Epoch 00024: val_auc did not improve from 0.95900\n",
      "227/227 [==============================] - 221s 974ms/step - loss: 0.1771 - accuracy: 0.6847 - auc: 0.8139 - val_loss: 0.2004 - val_accuracy: 0.9080 - val_auc: 0.9589\n",
      "Epoch 25/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1756 - accuracy: 0.6850 - auc: 0.8143\n",
      "Epoch 00025: val_auc did not improve from 0.95900\n",
      "227/227 [==============================] - 159s 699ms/step - loss: 0.1757 - accuracy: 0.6847 - auc: 0.8146 - val_loss: 0.2006 - val_accuracy: 0.9080 - val_auc: 0.9589\n",
      "Epoch 26/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1783 - accuracy: 0.6853 - auc: 0.8116\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 8.90728450997358e-09.\n",
      "\n",
      "Epoch 00026: val_auc did not improve from 0.95900\n",
      "227/227 [==============================] - 159s 699ms/step - loss: 0.1782 - accuracy: 0.6853 - auc: 0.8116 - val_loss: 0.2005 - val_accuracy: 0.9083 - val_auc: 0.9589\n",
      "Epoch 27/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1786 - accuracy: 0.6816 - auc: 0.8142\n",
      "Epoch 00027: val_auc did not improve from 0.95900\n",
      "227/227 [==============================] - 159s 699ms/step - loss: 0.1786 - accuracy: 0.6815 - auc: 0.8141 - val_loss: 0.2003 - val_accuracy: 0.9083 - val_auc: 0.9589\n",
      "Epoch 28/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1778 - accuracy: 0.6846 - auc: 0.8142\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 2.7612582531588715e-09.\n",
      "\n",
      "Epoch 00028: val_auc did not improve from 0.95900\n",
      "227/227 [==============================] - 159s 700ms/step - loss: 0.1778 - accuracy: 0.6845 - auc: 0.8143 - val_loss: 0.2004 - val_accuracy: 0.9083 - val_auc: 0.9589\n",
      "Epoch 29/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1758 - accuracy: 0.6872 - auc: 0.8147\n",
      "Epoch 00029: val_auc did not improve from 0.95900\n",
      "227/227 [==============================] - 159s 702ms/step - loss: 0.1756 - accuracy: 0.6874 - auc: 0.8148 - val_loss: 0.2004 - val_accuracy: 0.9079 - val_auc: 0.9589\n",
      "Epoch 30/30\n",
      "226/227 [============================>.] - ETA: 0s - loss: 0.1772 - accuracy: 0.6853 - auc: 0.8164\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 8.559900832594281e-10.\n",
      "\n",
      "Epoch 00030: val_auc did not improve from 0.95900\n",
      "227/227 [==============================] - 159s 701ms/step - loss: 0.1771 - accuracy: 0.6853 - auc: 0.8166 - val_loss: 0.2004 - val_accuracy: 0.9078 - val_auc: 0.9589\n",
      "42/42 [==============================] - 52s 1s/step\n",
      "toxic: 0.15375 pred: 0.26548043 0.185625\n",
      "AUC: 0.9589617033541089\n",
      "333/333 [==============================] - 85s 256ms/step\n",
      "mean: 0.31814954 0.2579452140663198\n",
      "                                                                 0\n",
      "seed                                                             3\n",
      "tpu_id                                                         t8a\n",
      "path                                                  jigsaw/r000/\n",
      "gcs                                                       hm-eu-w4\n",
      "dataset          ../input/jigsaw-mltc-ds/jigsaw_mltc_ds436001s.npz\n",
      "stages                                                          10\n",
      "epochs                                                          30\n",
      "weight_decay                                           1.19879e-06\n",
      "pos_weight                                                 2.94862\n",
      "optimizer                                                     LAMB\n",
      "lr                                                     3.23753e-05\n",
      "loss_fn                                                      focal\n",
      "label_smoothing                                          0.0154527\n",
      "gamma                                                      1.00809\n",
      "auc                                                       0.958962\n",
      "Best params: (0.9589617033541089, 0, {'optimizer': 'LAMB', 'lr': 3.2375274380947834e-05, 'weight_decay': 1.1987913313260122e-06, 'loss_fn': 'focal', 'label_smoothing': 0.015452685477698073, 'pos_weight': 2.948615582164439, 'gamma': 1.0080920769526096, 'epochs': 30, 'stages': 10, 'dataset': '../input/jigsaw-mltc-ds/jigsaw_mltc_ds436001s.npz', 'gcs': 'hm-eu-w4', 'path': 'jigsaw/r000/', 'tpu_id': 't8a', 'seed': 3})\n",
      "                                                                 0\n",
      "seed                                                             3\n",
      "tpu_id                                                         t8a\n",
      "path                                                  jigsaw/r000/\n",
      "gcs                                                       hm-eu-w4\n",
      "dataset          ../input/jigsaw-mltc-ds/jigsaw_mltc_ds436001s.npz\n",
      "stages                                                          10\n",
      "epochs                                                          30\n",
      "weight_decay                                           3.31015e-05\n",
      "pos_weight                                                 3.84656\n",
      "optimizer                                                     LAMB\n",
      "lr                                                     4.03727e-06\n",
      "loss_fn                                                      focal\n",
      "label_smoothing                                          0.0069451\n",
      "gamma                                                      1.31119\n",
      "Running on TPU  grpc://10.246.162.210:8470\n",
      "WARNING:tensorflow:TPU system t8a has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:TPU system t8a has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: t8a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: t8a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  8\n",
      "Path: gs://hm-eu-w4/jigsaw/r000//20200422_160437_t8a\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from train import train\n",
    "best = (0, None)\n",
    "\n",
    "for i in range(6):\n",
    "    params = dict(\n",
    "        optimizer=np.random.choice(['LAMB', 'AdamW']),\n",
    "        lr=10**np.random.uniform(low=-5.5, high=-4),\n",
    "        moving_average=0.999,\n",
    "        weight_decay=10**np.random.uniform(low=-7, high=-4),\n",
    "        loss_fn='focal',\n",
    "        label_smoothing=np.random.uniform(low=0.001, high=0.05),\n",
    "        pos_weight=np.random.uniform(low=1, high=6),\n",
    "        gamma=np.random.uniform(low=0.0, high=3.0),\n",
    "        epochs=30,\n",
    "        stages=10,\n",
    "        dataset='../input/jigsaw-mltc-ds/jigsaw_mltc_ds436001s.npz',\n",
    "        gcs='hm-eu-w4',\n",
    "        path=f'jigsaw/r000/',\n",
    "        tpu_id='t8a',\n",
    "        seed=3,\n",
    "    )\n",
    "\n",
    "    auc = train(**params)\n",
    "    if auc > best[0]:\n",
    "        best = (auc, i, params)\n",
    "        print('Best params:', best)\n",
    "\n",
    "print('### Grid Search Done:')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from train import train\n",
    "\n",
    "# from hyperopt import hp, fmin, tpe, space_eval, Trials\n",
    "# from hyperopt.mongoexp import MongoTrials\n",
    "\n",
    "# trials = Trials()\n",
    "# # trials = MongoTrials('mongo://localhost:1234/jigsaw_db/jobs', exp_key='r002')\n",
    "\n",
    "# # define a search space\n",
    "# space = dict(\n",
    "#     optimizer='LAMB', #hp.choice('optimizer', ['LAMB', 'AdamW']),\n",
    "#     lr=hp.choice('lr', np.logspace(-6, -4, num=99)),\n",
    "#     weight_decay=hp.choice('weight_decay', np.logspace(-7, -4, num=99)),\n",
    "# #     loss_fn='focal',\n",
    "#     label_smoothing=hp.choice('label_smoothing', np.linspace(0.001, 0.05, num=99)),\n",
    "# #     pos_weight=hp.choice('pos_weight', np.linspace(1, 6, num=99)),\n",
    "# #     gamma=hp.choice('gamma', np.linspace(0.0, 3.0, num=99)),\n",
    "#     epochs=30,\n",
    "#     stages=10,\n",
    "#     dataset='../input/jigsaw-mltc-ds/jigsaw_mltc_ds436001s.npz',\n",
    "#     gcs='hm-eu-w4',\n",
    "#     path=f'jigsaw/h000',\n",
    "#     tpu_id='t8a',\n",
    "#     seed=3,\n",
    "# )\n",
    "\n",
    "# # minimize the objective over the space\n",
    "# def objective(args):\n",
    "# #     print('### ASD ### !!! ### $$$ %%%% &&&&')\n",
    "#     return -train(**args)\n",
    "\n",
    "# best = fmin(objective, space, trials=trials, algo=tpe.suggest, max_evals=6)\n",
    "\n",
    "# print(space_eval(space, best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdb; pdb.pm()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03df225fb40c4a3cbddfdb6beddb0e4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "15ada43973ce43deabc26c111bc346e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ec7dd5ce7e04e4184f5c16e9d410e3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "23976f077e8c4855af1a1cfe193b60ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3fbc3a0e6fb14d8085d98270ec4b33b2",
       "placeholder": "​",
       "style": "IPY_MODEL_2a65d9d5af90464aa718587f9a121a1c",
       "value": " 5.07M/5.07M [00:01&lt;00:00, 2.89MB/s]"
      }
     },
     "2a65d9d5af90464aa718587f9a121a1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3e88f3383ac8472faef99555f2eb3cec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "3fbc3a0e6fb14d8085d98270ec4b33b2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4a4e5352a8714816a1eb15d297ef2077": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6481a898fe2e4e52bafb7bda11c7a9c6",
       "max": 5069051,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3e88f3383ac8472faef99555f2eb3cec",
       "value": 5069051
      }
     },
     "5bbd64c445e149a1894b2f195c93ed6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d73ea71b0f6f4970a15b4f60b4ce8c56",
       "max": 738,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1ec7dd5ce7e04e4184f5c16e9d410e3b",
       "value": 738
      }
     },
     "5eb82dd559dd49a2bdd9078f0289f13a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e39f3a70f25841049ddde333e84f9b2f",
       "max": 3271420488,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a2cbb4062d314b7faff832f5eab5cce6",
       "value": 3271420488
      }
     },
     "6481a898fe2e4e52bafb7bda11c7a9c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b45213384a34a549bd24c55d6e4b583": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "76625d00261a4c16b05a29bd9885e7ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b4adcdd0fb934b4e8b0f7efbef525f64",
       "placeholder": "​",
       "style": "IPY_MODEL_03df225fb40c4a3cbddfdb6beddb0e4b",
       "value": " 3.27G/3.27G [01:26&lt;00:00, 37.7MB/s]"
      }
     },
     "7d865efc6e0f4be886075b93553f8a0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9b6585770d8e4a83a6be952a064cc4dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a2cbb4062d314b7faff832f5eab5cce6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "b4adcdd0fb934b4e8b0f7efbef525f64": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b56982b3e6e945b98bb6ceff75718713": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4a4e5352a8714816a1eb15d297ef2077",
        "IPY_MODEL_23976f077e8c4855af1a1cfe193b60ef"
       ],
       "layout": "IPY_MODEL_9b6585770d8e4a83a6be952a064cc4dd"
      }
     },
     "cd0d1db27650445485ab49e819c306b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f4961b04478b45c48a12189728bf82a7",
       "placeholder": "​",
       "style": "IPY_MODEL_7d865efc6e0f4be886075b93553f8a0d",
       "value": " 738/738 [00:22&lt;00:00, 32.8B/s]"
      }
     },
     "ceb3bf5654dc4ab7aaab33ce7fcfa136": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5bbd64c445e149a1894b2f195c93ed6c",
        "IPY_MODEL_cd0d1db27650445485ab49e819c306b9"
       ],
       "layout": "IPY_MODEL_6b45213384a34a549bd24c55d6e4b583"
      }
     },
     "d73ea71b0f6f4970a15b4f60b4ce8c56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "deb54208870b488999cc305ae36d2560": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5eb82dd559dd49a2bdd9078f0289f13a",
        "IPY_MODEL_76625d00261a4c16b05a29bd9885e7ac"
       ],
       "layout": "IPY_MODEL_15ada43973ce43deabc26c111bc346e6"
      }
     },
     "e39f3a70f25841049ddde333e84f9b2f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4961b04478b45c48a12189728bf82a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
