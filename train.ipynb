{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting single_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile single_model.py\n",
    "\"\"\" build a TFAutoModel and load its data from npz or tfrec dataset \"\"\"\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from transformers import TFAutoModel\n",
    "\n",
    "\n",
    "def build_model(model_id='jplu/tf-xlm-roberta-large',\n",
    "                max_len=192, dropout=0.2,\n",
    "                **_):\n",
    "    \"\"\" build a TFAutoModel \"\"\"\n",
    "    transformer = TFAutoModel.from_pretrained(model_id)\n",
    "\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    sequence_output = transformer(input_word_ids)[0]\n",
    "    cls_token = sequence_output[:, 0, :]\n",
    "    if dropout > 0:\n",
    "        cls_token = Dropout(dropout)(cls_token)\n",
    "    out = Dense(1, activation='sigmoid')(cls_token)\n",
    "    model = Model(inputs=input_word_ids, outputs=out)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def np_dataset(dataset, batch_size, seed):\n",
    "    \"\"\" load npz datasets \"\"\"\n",
    "    array = np.load(dataset)\n",
    "    x_train, x_valid, x_test, y_train, y_valid = [array[k] for k in list(array)]\n",
    "    # Shuffle\n",
    "    x_train = pd.DataFrame(np.concatenate([x_train.T, [y_train]]).T\n",
    "                          ).sample(frac=1, random_state=seed).values\n",
    "    assert abs(x_train[..., :-1] - x_train[..., :-1].astype('int32')).max() == 0\n",
    "    x_train, y_train = x_train[..., :-1].astype('int32'), x_train[..., -1].astype('float32')\n",
    "    print(x_train.shape, x_valid.shape, x_test.shape, y_train.shape, y_valid.shape)\n",
    "\n",
    "    ## Set Datasets\n",
    "    auto_tune = tf.data.experimental.AUTOTUNE\n",
    "    train_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((x_train, y_train))\n",
    "        .repeat()\n",
    "        .shuffle(2048)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(auto_tune)\n",
    "    )\n",
    "\n",
    "    valid_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((x_valid, y_valid))\n",
    "        .batch(batch_size)\n",
    "        .cache()\n",
    "        .prefetch(auto_tune)\n",
    "    )\n",
    "\n",
    "    test_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices(x_test)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(auto_tune)\n",
    "    )\n",
    "\n",
    "    return train_dataset, valid_dataset, test_dataset\n",
    "\n",
    "\n",
    "def val_np_dataset(dataset='../input/jigsaw20-val-test-ds/jigsaw20_val_ds.npz', batch_size=128):\n",
    "    \"\"\" load npz datasets \"\"\"\n",
    "    array = np.load(dataset)\n",
    "    x_valid, x_test, y_valid = [array[k] for k in list(array)]\n",
    "    print(x_valid.shape, x_test.shape, y_valid.shape)\n",
    "\n",
    "    ## Set Datasets\n",
    "    auto_tune = tf.data.experimental.AUTOTUNE\n",
    "    valid_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices((x_valid, y_valid))\n",
    "        .batch(batch_size)\n",
    "        .cache()\n",
    "        .prefetch(auto_tune)\n",
    "    )\n",
    "\n",
    "    test_dataset = (\n",
    "        tf.data.Dataset\n",
    "        .from_tensor_slices(x_test)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(auto_tune)\n",
    "    )\n",
    "\n",
    "    return valid_dataset, test_dataset\n",
    "\n",
    "\n",
    "def tf_dataset(dataset, batch_size, max_len, seed):\n",
    "    \"\"\" load tfrec datasets \"\"\"\n",
    "    auto_tune = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "    train_dataset = (\n",
    "        load_tf_dataset(dataset+'train*.tfrec', max_len, seed)\n",
    "        .repeat()\n",
    "        .shuffle(2048)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(auto_tune)\n",
    "    )\n",
    "\n",
    "    valid_dataset, test_dataset = val_np_dataset(batch_size=batch_size)\n",
    "\n",
    "    return train_dataset, valid_dataset, test_dataset\n",
    "\n",
    "def load_tf_dataset(filenames, max_len, seed, ordered=False):\n",
    "    \"\"\" load a tfrec dataset \"\"\"\n",
    "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
    "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
    "    auto_tune = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "    def read_labeled_tfrecord(example, max_len=max_len):\n",
    "        \"\"\" decode a tfrec \"\"\"\n",
    "        tf_format = {\n",
    "            \"data\": tf.io.FixedLenFeature(max_len, tf.int64),\n",
    "            \"label\": tf.io.FixedLenFeature([], tf.float32),  # shape [] means single element\n",
    "        }\n",
    "        example = tf.io.parse_single_example(example, tf_format)\n",
    "        return example['data'], example['label']\n",
    "\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False # disable order, increase speed\n",
    "\n",
    "    # expand and shuffle files\n",
    "    filenames = tf.io.gfile.glob(filenames)\n",
    "    random.Random(seed).shuffle(filenames)\n",
    "    # automatically interleaves reads from multiple files\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=auto_tune)\n",
    "    # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.with_options(ignore_order)\n",
    "    dataset = dataset.map(read_labeled_tfrecord, num_parallel_calls=auto_tune)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No config file found, using default configuration\n",
      "\n",
      "--------------------------------------------------------------------\n",
      "Your code has been rated at 10.00/10 (previous run: 10.00/10, +0.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pylint3 single_model.py --ignored-modules=tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dual_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile dual_model.py\n",
    "\"\"\" build a dual TFAutoModel and load its data from npz or tfrec dataset \"\"\"\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from transformers import TFAutoModel\n",
    "\n",
    "\n",
    "def build_model(model_id1='bert-base-multilingual-cased',\n",
    "                model_id2='bert-base-multilingual-uncased',\n",
    "                max_len=192, dropout=0.2,\n",
    "                **_):\n",
    "    \"\"\" build a dual TFAutoModel \"\"\"\n",
    "    print(model_id1, model_id2)\n",
    "\n",
    "    transformer1 = TFAutoModel.from_pretrained(model_id1)\n",
    "    transformer2 = TFAutoModel.from_pretrained(model_id2)\n",
    "\n",
    "    input_word_ids1 = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids1\")\n",
    "    out1 = transformer1(input_word_ids1)\n",
    "\n",
    "    input_word_ids2 = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids2\")\n",
    "    out2 = transformer2(input_word_ids2)\n",
    "\n",
    "    sequence_output1 = out1[0]\n",
    "    sequence_output2 = out2[0]\n",
    "    cls_token1 = sequence_output1[:, 0, :]\n",
    "    cls_token2 = sequence_output2[:, 0, :]\n",
    "\n",
    "    x = Dropout(dropout)(cls_token1) + Dropout(dropout)(cls_token2)\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=[input_word_ids1, input_word_ids2], outputs=out)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def np_dataset(datasets, batch_size, seed):\n",
    "    \"\"\" load npz datasets \"\"\"\n",
    "    datasets = sorted(glob.glob(datasets))\n",
    "    print(datasets)\n",
    "\n",
    "    ## x_train1\n",
    "    array = np.load(datasets[0])\n",
    "    x_train, x_valid, x_test, y_train, y_valid = [array[k] for k in list(array)]\n",
    "    # Shuffle\n",
    "    x_train = pd.DataFrame(np.concatenate([x_train.T, [y_train]]).T\n",
    "                          ).sample(frac=1, random_state=seed).values\n",
    "    assert abs(x_train[..., :-1] - x_train[..., :-1].astype('int32')).max() == 0\n",
    "    x_train, y_train = x_train[..., :-1].astype('int32'), x_train[..., -1].astype('float32')\n",
    "    print(x_train.shape, x_valid.shape, x_test.shape, y_train.shape, y_valid.shape)\n",
    "\n",
    "    x_train1, x_valid1, x_test1 = x_train, x_valid, x_test\n",
    "\n",
    "    ## x_train2\n",
    "    array = np.load(datasets[1])\n",
    "    x_train, x_valid, x_test, y_train, y_valid = [array[k] for k in list(array)]\n",
    "    # Shuffle\n",
    "    x_train = pd.DataFrame(np.concatenate([x_train.T, [y_train]]).T\n",
    "                          ).sample(frac=1, random_state=seed).values\n",
    "    assert abs(x_train[..., :-1] - x_train[..., :-1].astype('int32')).max() == 0\n",
    "    x_train, y_train = x_train[..., :-1].astype('int32'), x_train[..., -1].astype('float32')\n",
    "    print(x_train.shape, x_valid.shape, x_test.shape, y_train.shape, y_valid.shape)\n",
    "\n",
    "    x_train2, x_valid2, x_test2 = x_train, x_valid, x_test\n",
    "\n",
    "    ## Set Datasets\n",
    "    auto_tune = tf.data.experimental.AUTOTUNE\n",
    "    train_dataset = (\n",
    "        tf.data.Dataset.zip((\n",
    "            tf.data.Dataset.from_tensor_slices((x_train1, x_train2)),\n",
    "            tf.data.Dataset.from_tensor_slices(y_train)\n",
    "        ))\n",
    "        .repeat()\n",
    "        .shuffle(2048)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(auto_tune)\n",
    "    )\n",
    "\n",
    "    valid_dataset = (\n",
    "        tf.data.Dataset.zip((\n",
    "            tf.data.Dataset.from_tensor_slices((x_valid1, x_valid2)),\n",
    "            tf.data.Dataset.from_tensor_slices(y_valid)\n",
    "        ))\n",
    "        .batch(batch_size)\n",
    "        .cache()\n",
    "        .prefetch(auto_tune)\n",
    "    )\n",
    "\n",
    "    test_dataset = (\n",
    "        tf.data.Dataset.zip((\n",
    "            tf.data.Dataset.from_tensor_slices((x_test1, x_test2)),\n",
    "            tf.data.Dataset.from_tensor_slices(np.ones(len(x_test1), dtype='float32'))\n",
    "        ))\n",
    "        .batch(batch_size)\n",
    "        .prefetch(auto_tune)\n",
    "    )\n",
    "\n",
    "    return train_dataset, valid_dataset, test_dataset\n",
    "\n",
    "\n",
    "def tf_dataset(*_):\n",
    "    \"\"\" load tfrec datasets \"\"\"\n",
    "    raise \"Not Implemented\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No config file found, using default configuration\n",
      "************* Module dual_model\n",
      "R: 13, 0: Too many local variables (18/15) (too-many-locals)\n",
      "C: 34, 4: Variable name \"x\" doesn't conform to snake_case naming style (invalid-name)\n",
      "R: 43, 0: Too many local variables (19/15) (too-many-locals)\n",
      "E: 98,75: Module 'numpy' has no 'float32' member (no-member)\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Your code has been rated at 8.30/10 (previous run: 9.36/10, -1.06)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pylint3 dual_model.py --ignored-modules=tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "\"\"\" build and train a TFAutoModel from npz or tfrec dataset \"\"\"\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from tqdm.notebook import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "# from tensorflow_addons.optimizers.utils import fit_bn\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from one_cycle_scheduler import OneCycleScheduler\n",
    "from visual import save_fig, plot_history\n",
    "from focal_loss import focal_loss\n",
    "\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "def compile_model(model,\n",
    "                  optimizer='LAMB', lr=2e-5, weight_decay=1e-6,\n",
    "                  loss_fn='bce', label_smoothing=0.01,\n",
    "                  pos_weight=5, gamma=2.0,  ## focal loss\n",
    "                  amp=False,\n",
    "                  **_):\n",
    "    \"\"\" compile the model with a loss function and an optimizer \"\"\"\n",
    "    if loss_fn == 'focal':\n",
    "        loss = focal_loss(pos_weight=pos_weight, gamma=gamma, label_smoothing=label_smoothing)\n",
    "    elif loss_fn == 'bce':\n",
    "        loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing)\n",
    "\n",
    "    if optimizer == 'LAMB':\n",
    "        opt = tfa.optimizers.LAMB(lr=lr, weight_decay_rate=weight_decay)\n",
    "    elif optimizer == 'AdamW':\n",
    "        opt = tfa.optimizers.AdamW(lr=lr, weight_decay=weight_decay)\n",
    "    print(opt)\n",
    "\n",
    "    if amp:\n",
    "        print('Using auto_mixed_precision.')\n",
    "        tf.config.optimizer.set_jit(True)\n",
    "        tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
    "        opt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt, 'dynamic')\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=loss,\n",
    "        metrics=[tf.keras.metrics.AUC(name='auc')]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def train_model(model, strategy, checkpoint_path, datasets,\n",
    "                epochs=30, steps_per_epoch=250,\n",
    "                lr=2e-5, one_cycle=True, warm_up=1,\n",
    "                mom_min=0.85, mom_max=0.95,\n",
    "                div_factor=100, final_div_factor=250,\n",
    "                callback=None,\n",
    "                **_):\n",
    "    \"\"\" train the given model \"\"\"\n",
    "    train_dataset, valid_dataset, test_dataset = datasets\n",
    "\n",
    "    ## Train\n",
    "    callbacks = [] if callback is None else [callback]\n",
    "    callbacks.append(tf.keras.callbacks.EarlyStopping(monitor='val_auc', min_delta=1e-4,\n",
    "                                                      mode='max', patience=epochs//5, verbose=1,\n",
    "                                                      restore_best_weights=False)) # restore later\n",
    "\n",
    "    if one_cycle:\n",
    "        callbacks.append(OneCycleScheduler(lr_max=lr, steps=steps_per_epoch*epochs,\n",
    "                                           mom_min=mom_min, mom_max=mom_max,\n",
    "                                           phase_1_pct=warm_up/epochs,\n",
    "                                           div_factor=div_factor,\n",
    "                                           final_div_factor=final_div_factor))\n",
    "    else:\n",
    "        callbacks.append(tf.keras.callbacks.ReduceLROnPlateau(monitor='val_auc', factor=0.31,\n",
    "                                                              patience=2, cooldown=1, mode='max',\n",
    "                                                              verbose=1, min_delta=1e-4))\n",
    "\n",
    "    callbacks.append(tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                        monitor='val_auc',\n",
    "                                                        verbose=1, mode='max',\n",
    "                                                        save_best_only=True,\n",
    "                                                        save_weights_only=True))\n",
    "    print(callbacks)\n",
    "\n",
    "    model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=valid_dataset,\n",
    "        epochs=epochs,\n",
    "        callbacks=callbacks,\n",
    "    )\n",
    "\n",
    "    # load best\n",
    "    if epochs > 1:\n",
    "        # latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "        with strategy.scope():\n",
    "            model.load_weights(checkpoint_path)\n",
    "\n",
    "    return (model,\n",
    "            model.predict(valid_dataset, verbose=1),\n",
    "            model.predict(test_dataset, verbose=1))\n",
    "\n",
    "\n",
    "\n",
    "def setup_tpu(tpu_id):\n",
    "    \"\"\" resolve a tpu cluster \"\"\"\n",
    "    if tpu_id is None:\n",
    "        with open('tpu', 'r') as content_file:\n",
    "            tpu_id = content_file.read()\n",
    "            print(dict(tpu_id=tpu_id))\n",
    "\n",
    "    ## Detect hardware, return appropriate distribution strategy\n",
    "    try:\n",
    "        # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "        # set: this is always the case on Kaggle.\n",
    "        tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=tpu_id)\n",
    "        print('Running on TPU ', tpu.master())\n",
    "    except ValueError:\n",
    "        tpu = None\n",
    "\n",
    "    if tpu:\n",
    "        tf.config.experimental_connect_to_cluster(tpu)\n",
    "        tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    else:\n",
    "        # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "        strategy = tf.distribute.get_strategy()\n",
    "    print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n",
    "    return strategy\n",
    "\n",
    "\n",
    "\n",
    "##################\n",
    "###### MAIN ######\n",
    "##################\n",
    "\n",
    "def train(dataset, gcs='hm-eu-w4', path='jigsaw/test',\n",
    "          seed=0, max_len=192, batch_size=28,\n",
    "          tpu_id=None, dual=False,\n",
    "          **kwargs):\n",
    "    \"\"\" build and train a TFAutoModel from npz or tfrec dataset \"\"\"\n",
    "    params = dict(locals())\n",
    "    params.update(kwargs)\n",
    "    params = pd.DataFrame(params, index=[0])\n",
    "    del params['kwargs']\n",
    "    if params.loc[0, 'loss_fn'] != 'focal':\n",
    "        del params['gamma']\n",
    "        del params['pos_weight']\n",
    "    kw_params = params.T[0].to_dict()\n",
    "    print(params.T)\n",
    "    gc.collect()\n",
    "\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "    strategy = setup_tpu(tpu_id)\n",
    "\n",
    "    ## Configuration\n",
    "    path = f'{path}/{time.strftime(\"%Y%m%d_%H%M%S\")}_{tpu_id}'\n",
    "    gcs_path = f'gs://{gcs}/{path}'\n",
    "    checkpoint_path = f\"{gcs_path}/best_model.tf\"\n",
    "    print('gcs_path:', gcs_path)\n",
    "    params['gcs_path'] = gcs_path\n",
    "    batch_size = batch_size * strategy.num_replicas_in_sync\n",
    "    print('batch_size:', batch_size)\n",
    "\n",
    "    if dual: ## HACK: dynamic import :/\n",
    "        from dual_model import build_model, tf_dataset, np_dataset\n",
    "    else:\n",
    "        from single_model import build_model, tf_dataset, np_dataset\n",
    "\n",
    "    if dataset.startswith('gs://'):\n",
    "        datasets = tf_dataset(dataset, batch_size, max_len, seed)\n",
    "    else:\n",
    "        datasets = np_dataset(dataset, batch_size, seed)\n",
    "\n",
    "    ## Load and Train\n",
    "    with strategy.scope():\n",
    "        model = build_model(**kw_params)\n",
    "        model = compile_model(model, **kw_params)\n",
    "    model, preds, sub_y = train_model(model, strategy, checkpoint_path, datasets, **kw_params)\n",
    "\n",
    "    ## Save results\n",
    "    plot_history(model.history, path, gcs)\n",
    "    history = pd.DataFrame(model.history.history)\n",
    "    print(history)\n",
    "    history.to_csv(f'{gcs_path}/history.csv', index=False)\n",
    "\n",
    "    ## Load Dataset\n",
    "    comp_ds = '../input/jigsaw-multilingual-toxic-comment-classification'\n",
    "    valid = pd.read_csv(f'{comp_ds}/validation.csv')\n",
    "#     test = pd.read_csv(f'{comp_ds}/test.csv')\n",
    "    sub = pd.read_csv(f'{comp_ds}/sample_submission.csv')\n",
    "\n",
    "    valid['pred'] = preds\n",
    "    valid.to_csv(f'{gcs_path}/valid_oof.csv', index=False)\n",
    "\n",
    "    valid.groupby('toxic').pred.hist(bins=100, log=True, alpha=0.5)\n",
    "    plt.legend([0, 1])\n",
    "    save_fig('valid_hist.png', path, gcs)\n",
    "\n",
    "    valid[valid.toxic == 1].groupby('lang').pred.hist(bins=50, log=True, alpha=0.34)\n",
    "    plt.legend(valid.lang.unique())\n",
    "    save_fig('valid_toxic_hist.png', path, gcs)\n",
    "\n",
    "    valid_auc = roc_auc_score(valid.toxic, valid.pred)\n",
    "    print('AUC:', valid_auc,\n",
    "          'toxic:', valid.toxic.mean(),\n",
    "          'pred:', valid.pred.mean(),\n",
    "          'ratio:', (valid.pred > 0.5).mean())\n",
    "\n",
    "    ## Submission\n",
    "    sub['toxic'] = sub_y\n",
    "    sub.to_csv(f'{gcs_path}/submission.csv', index=False)\n",
    "\n",
    "    sub.toxic.hist(bins=100, log=True)\n",
    "    save_fig('sub_hist.png', path, gcs)\n",
    "    print('mean:', sub.toxic.mean(), 'ratio:', (sub.toxic > 0.5).mean())\n",
    "\n",
    "    ## Save params\n",
    "    params['auc'] = valid_auc\n",
    "    params.to_csv(f'{gcs_path}/params{valid_auc:04f}.csv', index=False)\n",
    "    print(params.T)\n",
    "\n",
    "    return valid_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No config file found, using default configuration\n",
      "************* Module train\n",
      "C: 26, 0: Argument name \"lr\" doesn't conform to snake_case naming style (invalid-name)\n",
      "R: 26, 0: Too many arguments (9/5) (too-many-arguments)\n",
      "C: 60, 0: Argument name \"lr\" doesn't conform to snake_case naming style (invalid-name)\n",
      "R: 60, 0: Too many arguments (14/5) (too-many-arguments)\n",
      "R: 60, 0: Too many local variables (19/15) (too-many-locals)\n",
      "R:146, 0: Too many arguments (8/5) (too-many-arguments)\n",
      "R:146, 0: Too many local variables (26/15) (too-many-locals)\n",
      "R:146, 0: Too many statements (61/50) (too-many-statements)\n",
      "\n",
      "------------------------------------------------------------------\n",
      "Your code has been rated at 9.35/10 (previous run: 9.35/10, +0.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pylint3 train.py --ignored-modules=tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 0\n",
      "dual                                                          True\n",
      "tpu_id                                                         t8a\n",
      "batch_size                                                       8\n",
      "max_len                                                        192\n",
      "seed                                                            78\n",
      "path                                                   jigsaw/test\n",
      "gcs                                                       hm-eu-w4\n",
      "dataset          ../input/jigsaw-translated-distilled-ds5/jigsa...\n",
      "optimizer                                                    AdamW\n",
      "lr                                                     7.77939e-05\n",
      "weight_decay                                           4.46321e-07\n",
      "loss_fn                                                      focal\n",
      "label_smoothing                                          0.0215838\n",
      "pos_weight                                                 4.30223\n",
      "gamma                                                      2.08432\n",
      "warm_up                                                     3.2895\n",
      "epochs                                                           1\n",
      "steps_per_epoch                                                  5\n",
      "Running on TPU  grpc://10.246.162.210:8470\n",
      "REPLICAS:  8\n",
      "gcs_path: gs://hm-eu-w4/jigsaw/test/20200503_105704_t8a\n",
      "batch_size: 64\n",
      "['../input/jigsaw-translated-distilled-ds5/jigsaw20_ds985588s5_ml_bert-base-multilingual-cased.npz', '../input/jigsaw-translated-distilled-ds5/jigsaw20_ds985588s5_ml_bert-base-multilingual-uncased.npz']\n",
      "(985588, 192) (8000, 192) (63812, 192) (985588,) (8000,)\n",
      "(985588, 192) (8000, 192) (63812, 192) (985588,) (8000,)\n",
      "bert-base-multilingual-cased bert-base-multilingual-uncased\n",
      "<tensorflow_addons.optimizers.weight_decay_optimizers.AdamW object at 0x7f66b4ff5a58>\n",
      "[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f67e3438c50>, <one_cycle_scheduler.OneCycleScheduler object at 0x7f67540ff160>, <tensorflow.python.keras.callbacks.ModelCheckpoint object at 0x7f67540b2358>]\n",
      "Train for 5 steps, validate for 125 steps\n",
      "4/5 [=======================>......] - ETA: 47s - loss: 0.9524 - auc: 0.4260 \n",
      "Epoch 00001: val_auc improved from -inf to 0.43897, saving model to gs://hm-eu-w4/jigsaw/test/20200503_105704_t8a/best_model.tf\n",
      "5/5 [==============================] - 227s 45s/step - loss: 0.9148 - auc: 0.5970 - val_loss: 0.5271 - val_auc: 0.4390\n",
      "125/125 [==============================] - 30s 239ms/step\n",
      "998/998 [==============================] - 97s 97ms/step\n",
      "       loss       auc  val_loss   val_auc\n",
      "0  0.914833  0.596968  0.527122  0.438975\n",
      "AUC: 0.4390225888964946 toxic: 0.15375 pred: 0.4424679 ratio: 0.4585\n",
      "mean: 0.4423179 ratio: 0.46814078856641383\n",
      "                                                                 0\n",
      "dual                                                          True\n",
      "tpu_id                                                         t8a\n",
      "batch_size                                                       8\n",
      "max_len                                                        192\n",
      "seed                                                            78\n",
      "path                                                   jigsaw/test\n",
      "gcs                                                       hm-eu-w4\n",
      "dataset          ../input/jigsaw-translated-distilled-ds5/jigsa...\n",
      "optimizer                                                    AdamW\n",
      "lr                                                     7.77939e-05\n",
      "weight_decay                                           4.46321e-07\n",
      "loss_fn                                                      focal\n",
      "label_smoothing                                          0.0215838\n",
      "pos_weight                                                 4.30223\n",
      "gamma                                                      2.08432\n",
      "warm_up                                                     3.2895\n",
      "epochs                                                           1\n",
      "steps_per_epoch                                                  5\n",
      "gcs_path             gs://hm-eu-w4/jigsaw/test/20200503_105704_t8a\n",
      "auc                                                       0.439023\n",
      "Best params: (0.4390225888964946, 0, {'optimizer': 'AdamW', 'lr': 7.7793928116876e-05, 'weight_decay': 4.4632119511874887e-07, 'loss_fn': 'focal', 'label_smoothing': 0.0215837804861886, 'pos_weight': 4.3022259998640715, 'gamma': 2.0843153477082232, 'warm_up': 3.2894958660580786, 'epochs': 1, 'steps_per_epoch': 5, 'batch_size': 8, 'dataset': '../input/jigsaw-translated-distilled-ds5/jigsaw20_ds985588s5_ml_bert-base-multilingual-*.npz', 'path': 'jigsaw/test', 'tpu_id': 't8a', 'seed': 78, 'dual': True})\n",
      "### Grid Search Done:\n",
      "(0.4390225888964946, 0, {'optimizer': 'AdamW', 'lr': 7.7793928116876e-05, 'weight_decay': 4.4632119511874887e-07, 'loss_fn': 'focal', 'label_smoothing': 0.0215837804861886, 'pos_weight': 4.3022259998640715, 'gamma': 2.0843153477082232, 'warm_up': 3.2894958660580786, 'epochs': 1, 'steps_per_epoch': 5, 'batch_size': 8, 'dataset': '../input/jigsaw-translated-distilled-ds5/jigsaw20_ds985588s5_ml_bert-base-multilingual-*.npz', 'path': 'jigsaw/test', 'tpu_id': 't8a', 'seed': 78, 'dual': True})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from train import train\n",
    "\n",
    "best = (0, None)\n",
    "\n",
    "for i in range(1):\n",
    "    params = dict(\n",
    "        optimizer=np.random.choice(['LAMB', 'AdamW']),\n",
    "        lr=10**np.random.uniform(low=-5.5, high=-4),\n",
    "        weight_decay=10**np.random.uniform(low=-6.5, high=-4.5),\n",
    "        loss_fn='focal',\n",
    "        label_smoothing=np.random.uniform(low=0.01, high=0.04),\n",
    "        pos_weight=np.random.uniform(low=1.5, high=5),\n",
    "        gamma=np.random.uniform(low=1.0, high=2.5),\n",
    "        warm_up=np.random.uniform(low=1, high=5),\n",
    "        epochs=1, #np.random.randint(low=28, high=38),\n",
    "        steps_per_epoch=5,\n",
    "        batch_size=8,\n",
    "#         dataset='gs://hm-eu-w4/jigsaw/translated-distilled-ds4/',\n",
    "        dataset='../input/jigsaw-translated-distilled-ds5/jigsaw20_ds985588s5_ml_bert-base-multilingual-*.npz',\n",
    "        dual=True,\n",
    "        path=f'jigsaw/test',\n",
    "        tpu_id='t8a',\n",
    "        seed=np.random.randint(999),\n",
    "    )\n",
    "\n",
    "    auc = train(**params)\n",
    "    if auc > best[0]:\n",
    "        best = (auc, i, params)\n",
    "        print('Best params:', best)\n",
    "\n",
    "print('### Grid Search Done:')\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pdb; pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread('valid_hist.png')\n",
    "_ = plt.imshow(img)\n",
    "plt.show()\n",
    "img = mpimg.imread('valid_toxic_hist.png')\n",
    "_ = plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03df225fb40c4a3cbddfdb6beddb0e4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "15ada43973ce43deabc26c111bc346e6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1ec7dd5ce7e04e4184f5c16e9d410e3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "23976f077e8c4855af1a1cfe193b60ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3fbc3a0e6fb14d8085d98270ec4b33b2",
       "placeholder": "​",
       "style": "IPY_MODEL_2a65d9d5af90464aa718587f9a121a1c",
       "value": " 5.07M/5.07M [00:01&lt;00:00, 2.89MB/s]"
      }
     },
     "2a65d9d5af90464aa718587f9a121a1c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3e88f3383ac8472faef99555f2eb3cec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "3fbc3a0e6fb14d8085d98270ec4b33b2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4a4e5352a8714816a1eb15d297ef2077": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6481a898fe2e4e52bafb7bda11c7a9c6",
       "max": 5069051,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3e88f3383ac8472faef99555f2eb3cec",
       "value": 5069051
      }
     },
     "5bbd64c445e149a1894b2f195c93ed6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d73ea71b0f6f4970a15b4f60b4ce8c56",
       "max": 738,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1ec7dd5ce7e04e4184f5c16e9d410e3b",
       "value": 738
      }
     },
     "5eb82dd559dd49a2bdd9078f0289f13a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e39f3a70f25841049ddde333e84f9b2f",
       "max": 3271420488,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a2cbb4062d314b7faff832f5eab5cce6",
       "value": 3271420488
      }
     },
     "6481a898fe2e4e52bafb7bda11c7a9c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b45213384a34a549bd24c55d6e4b583": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "76625d00261a4c16b05a29bd9885e7ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b4adcdd0fb934b4e8b0f7efbef525f64",
       "placeholder": "​",
       "style": "IPY_MODEL_03df225fb40c4a3cbddfdb6beddb0e4b",
       "value": " 3.27G/3.27G [01:26&lt;00:00, 37.7MB/s]"
      }
     },
     "7d865efc6e0f4be886075b93553f8a0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9b6585770d8e4a83a6be952a064cc4dd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a2cbb4062d314b7faff832f5eab5cce6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "b4adcdd0fb934b4e8b0f7efbef525f64": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b56982b3e6e945b98bb6ceff75718713": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4a4e5352a8714816a1eb15d297ef2077",
        "IPY_MODEL_23976f077e8c4855af1a1cfe193b60ef"
       ],
       "layout": "IPY_MODEL_9b6585770d8e4a83a6be952a064cc4dd"
      }
     },
     "cd0d1db27650445485ab49e819c306b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_f4961b04478b45c48a12189728bf82a7",
       "placeholder": "​",
       "style": "IPY_MODEL_7d865efc6e0f4be886075b93553f8a0d",
       "value": " 738/738 [00:22&lt;00:00, 32.8B/s]"
      }
     },
     "ceb3bf5654dc4ab7aaab33ce7fcfa136": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5bbd64c445e149a1894b2f195c93ed6c",
        "IPY_MODEL_cd0d1db27650445485ab49e819c306b9"
       ],
       "layout": "IPY_MODEL_6b45213384a34a549bd24c55d6e4b583"
      }
     },
     "d73ea71b0f6f4970a15b4f60b4ce8c56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "deb54208870b488999cc305ae36d2560": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5eb82dd559dd49a2bdd9078f0289f13a",
        "IPY_MODEL_76625d00261a4c16b05a29bd9885e7ac"
       ],
       "layout": "IPY_MODEL_15ada43973ce43deabc26c111bc346e6"
      }
     },
     "e39f3a70f25841049ddde333e84f9b2f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4961b04478b45c48a12189728bf82a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
